{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting replicate\n",
      "  Downloading replicate-0.24.0-py3-none-any.whl.metadata (23 kB)\n",
      "Collecting httpx<1,>=0.21.0 (from replicate)\n",
      "  Using cached httpx-0.27.0-py3-none-any.whl.metadata (7.2 kB)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.10/site-packages (from replicate) (23.2)\n",
      "Collecting pydantic>1 (from replicate)\n",
      "  Downloading pydantic-2.6.4-py3-none-any.whl.metadata (85 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.1/85.1 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.10/site-packages (from replicate) (4.10.0)\n",
      "Collecting anyio (from httpx<1,>=0.21.0->replicate)\n",
      "  Using cached anyio-4.3.0-py3-none-any.whl.metadata (4.6 kB)\n",
      "Requirement already satisfied: certifi in /usr/local/lib/python3.10/site-packages (from httpx<1,>=0.21.0->replicate) (2024.2.2)\n",
      "Collecting httpcore==1.* (from httpx<1,>=0.21.0->replicate)\n",
      "  Using cached httpcore-1.0.4-py3-none-any.whl.metadata (20 kB)\n",
      "Requirement already satisfied: idna in /usr/local/lib/python3.10/site-packages (from httpx<1,>=0.21.0->replicate) (3.6)\n",
      "Collecting sniffio (from httpx<1,>=0.21.0->replicate)\n",
      "  Downloading sniffio-1.3.1-py3-none-any.whl.metadata (3.9 kB)\n",
      "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.21.0->replicate)\n",
      "  Using cached h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
      "Collecting annotated-types>=0.4.0 (from pydantic>1->replicate)\n",
      "  Using cached annotated_types-0.6.0-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting pydantic-core==2.16.3 (from pydantic>1->replicate)\n",
      "  Downloading pydantic_core-2.16.3-cp310-cp310-macosx_10_12_x86_64.whl.metadata (6.5 kB)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /Users/abrarsyed/Library/Python/3.10/lib/python/site-packages (from anyio->httpx<1,>=0.21.0->replicate) (1.2.0)\n",
      "Downloading replicate-0.24.0-py3-none-any.whl (37 kB)\n",
      "Using cached httpx-0.27.0-py3-none-any.whl (75 kB)\n",
      "Using cached httpcore-1.0.4-py3-none-any.whl (77 kB)\n",
      "Downloading pydantic-2.6.4-py3-none-any.whl (394 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m394.9/394.9 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading pydantic_core-2.16.3-cp310-cp310-macosx_10_12_x86_64.whl (1.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m13.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hUsing cached annotated_types-0.6.0-py3-none-any.whl (12 kB)\n",
      "Using cached anyio-4.3.0-py3-none-any.whl (85 kB)\n",
      "Downloading sniffio-1.3.1-py3-none-any.whl (10 kB)\n",
      "Using cached h11-0.14.0-py3-none-any.whl (58 kB)\n",
      "Installing collected packages: sniffio, pydantic-core, h11, annotated-types, pydantic, httpcore, anyio, httpx, replicate\n",
      "Successfully installed annotated-types-0.6.0 anyio-4.3.0 h11-0.14.0 httpcore-1.0.4 httpx-0.27.0 pydantic-2.6.4 pydantic-core-2.16.3 replicate-0.24.0 sniffio-1.3.1\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3.10 -m pip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install replicate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import replicate\n",
    "import json\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set your Replicate API token\n",
    "os.environ['REPLICATE_API_TOKEN'] = 'r8_0iFdno442nIMFzg6bkFaLJGDMXJVCaC0RPhoh'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_profiles = [\n",
    "    (\"18-22 years old\", \"Woman\", \"Asian\", \"Bachelor’s degree\", \"Less than 1 year\"),\n",
    "    (\"27-35 years old\", \"Man\", \"White\", \"Professional degree\", \"3-5 years\"),\n",
    "    (\"23-26 years old\", \"Woman\", \"White\", \"Master's degree\", \"1-3 years\"),\n",
    "    (\"27-35 years old\", \"Man\", \"Asian\", \"Bachelor's degree\", \"Less than 1 year\"),\n",
    "    (\"18-22 years old\", \"Woman\", \"White\", \"Professional degree\", \"3-5 years\"),\n",
    "    (\"23-26 years old\", \"Man\", \"Asian\", \"Master's degree\", \"Less than 1 year\"),\n",
    "    (\"27-35 years old\", \"Woman\", \"White\", \"Bachelor's degree\", \"1-3 years\"),\n",
    "    (\"18-22 years old\", \"Man\", \"Asian\", \"Professional degree\", \"1-3 years\"),\n",
    "    (\"23-26 years old\", \"Woman\", \"Asian\", \"Bachelor’s degree\", \"3-5 years\"),\n",
    "    (\"27-35 years old\", \"Man\", \"White\", \"Master’s degree\", \"Less than 1 year\"),\n",
    "\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the questionnaire\n",
    "questionnaire = [\n",
    "    {\n",
    "        \"question\": \"What is your preferred development environment?\",\n",
    "        \"answers\": {\n",
    "            \"option_1\": \"Windows\",\n",
    "            \"option_2\": \"macOS\",\n",
    "            \"option_3\": \"Linux\",\n",
    "            # \"option_4\": \"Other:\"\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"How do you learn to code? Please select all that apply.\",\n",
    "        \"answers\": {\n",
    "            \"option_1\": \"Online Courses or Certification\",\n",
    "            \"option_2\": \"Books\",\n",
    "            \"option_3\": \"School (i.e., University, College, etc.)\",\n",
    "            \"option_4\": \"Coding Bootcamp\",\n",
    "            # \"option_5\": \"Other:\"\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"What is the biggest challenge you face as a developer?\",\n",
    "        \"answers\": {\n",
    "            \"option_1\": \"Keeping up with new technologies\",\n",
    "            \"option_2\": \"Work-life balance\",\n",
    "            \"option_3\": \"Understanding existing codebases\",\n",
    "            \"option_4\": \"Time management\"\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"When choosing a programming language for a new project you prioritize:\",\n",
    "        \"answers\": {\n",
    "            \"option_1\": \"The language's performance and scalability\",\n",
    "            \"option_2\": \"The development team's familiarity with the language\",\n",
    "            \"option_3\": \"The language's community support and ecosystem\",\n",
    "            \"option_4\": \"The specific requirements of the project\"\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"How do you communicate effectively with teammates to collaborate while adhering to the timelines?\",\n",
    "        \"answers\": {\n",
    "            \"option_1\": \"Use project management tools to assign tasks and track progress ensuring everyone is aware of deadlines.\",\n",
    "            \"option_2\": \"Schedule regular meetings for updates and coordination but keep them concise to avoid taking too much time away from work.\",\n",
    "            \"option_3\": \"Rely on informal chats and emails for quick updates trusting team members to manage their time efficiently.\",\n",
    "            \"option_4\": \"Implement a combination of written documentation for clarity and regular check-ins for personal engagement and immediate feedback.\"\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"How do you ensure that you stay up-to-date with industry changes as a software developer? Please select all that apply.\",\n",
    "        \"answers\": {\n",
    "            \"option_1\": \"Regularly read industry blogs, websites, and journals to learn about the latest trends and technologies.\",\n",
    "            \"option_2\": \"Attend workshops, conferences, and webinars to gain insights from industry leaders and peers.\",\n",
    "            \"option_3\": \"Participate in online courses and certification programs to acquire new skills and knowledge.\",\n",
    "            \"option_4\": \"Engage in open-source projects and coding communities to get hands-on experience with cutting-edge technologies.\"\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"How do you balance between innovation and meeting project deadlines?\",\n",
    "        \"answers\": {\n",
    "            \"option_1\": \"Prioritize innovation over deadlines\",\n",
    "            \"option_2\": \"Focus solely on meeting deadlines\",\n",
    "            \"option_3\": \"Allocate specific time for research and innovation\",\n",
    "            \"option_4\": \"Adjust project scopes to include innovation\"\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"Software development contributes to societal challenges by:. Please select all that apply\",\n",
    "        \"answers\": {\n",
    "            \"option_1\": \"Improving healthcare through technology, such as telemedicine platforms and health tracking apps\",\n",
    "            \"option_2\": \"Enhancing education with e-learning platforms, interactive learning tools, and virtual classrooms\",\n",
    "            \"option_3\": \"Addressing climate change with environmental monitoring systems, carbon footprint calculators, and energy efficiency applications\",\n",
    "            \"option_4\": \"Supporting economic development through fintech solutions, e-commerce platforms, and digital marketplaces\"\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"A company uses an AI system to monitor its employees' productivity. The AI suggests firing an employee based on low productivity, but the employee is going through a tough personal time. How should the company proceed?\",\n",
    "        \"answers\": {\n",
    "            \"option_1\": \"Follow the AI’s suggestion and fire the employee\",\n",
    "            \"option_2\": \"Ignore the AI’s suggestion and keep the employee\",\n",
    "            \"option_3\": \"Use the AI’s suggestion as one of several factors in the decision\",\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"You're assigned to a project that requires expertise in a programming language you're not familiar with. The deadline is tight. What is your strategy to tackle this situation?\",\n",
    "        \"answers\": {\n",
    "            \"option_1\": \"Spend time upfront to learn the basics of the language\",\n",
    "            \"option_2\": \"Use your existing knowledge and adapt as you go\",\n",
    "            \"option_3\": \"Seek assistance from a colleague who knows the language\",\n",
    "            \"option_4\": \"Suggest reallocating the project to someone with the necessary expertise\",\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"You discover a critical bug right before a software release. What immediate action do you take?\",\n",
    "        \"answers\": {\n",
    "            \"option_1\": \"Proceed with the release as planned and fix the bug in a subsequent patch\",\n",
    "            \"option_2\": \"Delay the release to assess and fix the bug, ensuring the product meets quality standards\",\n",
    "            \"option_3\": \"Release a limited beta version to a select group of users for further testing while addressing the bug\",\n",
    "            \"option_4\": \"Communicate with stakeholders about the issue and seek their input on how to proceed\",\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"question\": \" In a professional setting, if your team is supposed to deliver a SaaS product within a two-day timeframe, and you discover a critical bug in the software, how would you address and handle this situation?\",\n",
    "        \"answers\": {\n",
    "            \"option_1\": \"Ignore the bug and proceed with the delivery as planned, with the intention of fixing the bug in the next update.\",\n",
    "            \"option_2\": \"Inform your team leader or project manager about the bug immediately, and work collaboratively to assess its impact and decide on the next steps\",\n",
    "            \"option_3\": \"Delay the delivery without informing stakeholders to buy time for fixing the bug\",\n",
    "            \"option_4\": \"Document the bug and send an email to the client explaining the issue, suggesting a new timeline for delivery\",\n",
    "            \"option_5\": \"Prioritize the bug based on its severity and impact, and if it's critical, reallocate resources to fix it immediately, even if this means pushing back the delivery date\",\n",
    "        }\n",
    "    },\n",
    "\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_response(response, answer_options):\n",
    "    selected_options = []\n",
    "    for option_id in answer_options.keys():  # Iterate over option_ids only\n",
    "        if option_id in response:\n",
    "            selected_options.append(option_id)\n",
    "    return ', '.join(selected_options) if selected_options else 'None'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def call_replicate(question, profile, answer_options):\n",
    "#     age, gender, ethnicity, education, exp = profile\n",
    "#     profile_desc = f\"{age} old {gender} of {ethnicity} ethnicity with a {education} and {exp} of coding experience\"\n",
    "\n",
    "#     # Constructing a string with all answer options\n",
    "#     options_str = \"\\n\".join([f\"{key}: {value}\" for key, value in answer_options.items()])\n",
    "\n",
    "#     # Adding examples for different types of responses\n",
    "#     example_single = \"Example (single correct): 'option_1'\"\n",
    "#     example_multiple = \"Example (multiple correct): 'option_1, option_2\"\n",
    "#     example_other = \"Only choose this option if you don't see the other option apt. Example (other option): 'option_4: Other: [Your Custom response]'\"\n",
    "#     response_format = \"option_id: [full text from choice]\"\n",
    "#     # Prepare the full prompt\n",
    "    # prompt = f\"\"\" \n",
    "    #                 Answer the following question: {question.strip()}\n",
    "    #                 The options to the question are given here:{options_str}\n",
    "                    \n",
    "    #                 Here are a few examples : \n",
    "    #                 {example_single}\\n{example_multiple}\\n{example_other}\n",
    "                \n",
    "    #                 Do not provide any explanations for your answers, simply choose one of the options and strictly\n",
    "    #                 answer in this format : \"option_id\"\n",
    "    # \"\"\"\n",
    "\n",
    "#     # Set additional parameters for the Replicate API\n",
    "#     system_prompt = f\"You are a {profile_desc}.\"\n",
    "#     prompt_template = f\"[INST] {prompt} [/INST]\"\n",
    "\n",
    "#     # Run the model and stream the output\n",
    "#     output_text = \"\"\n",
    "#     output = replicate.run(\n",
    "#         \"meta/llama-2-7b-chat:f1d50bb24186c52daae319ca8366e53debdaa9e0ae7ff976e918df752732ccc4\",\n",
    "#         input={\n",
    "#             \"top_p\": 1,\n",
    "#             \"prompt\": prompt_template,\n",
    "#             \"system_prompt\": system_prompt,\n",
    "#             \"temperature\": 0.75,\n",
    "#             \"repetition_penalty\": 1\n",
    "#         }\n",
    "#     )\n",
    "\n",
    "#     for item in output:\n",
    "#         output_text += str(item)\n",
    "\n",
    "#     return output_text.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "def call_replicate(question, profile, answer_options, next_question_start):\n",
    "    age, gender, ethnicity, education, exp = profile\n",
    "    profile_desc = f\"{age} old {gender} of {ethnicity} ethnicity with a {education} and {exp} of coding experience\"\n",
    "\n",
    "    # Constructing a string with all answer options for reference in the prompt\n",
    "    options_str = \"\\n\".join([f\"{key}: {value}\" for key, value in answer_options.items()])\n",
    "\n",
    "    # Adding stop sequences\n",
    "    stop_sequences = [\"<end>\", \"<stop>\", next_question_start]\n",
    "\n",
    "    # Prepare the full prompt with examples and instruction to only reply with option_id\n",
    "    prompt = f\"\"\" \n",
    "                [INST] <<SYS>>You are a {profile_desc}. Answer the following question by choosing from the given options.<</SYS>>\\n\n",
    "                Question: {question.strip()}\\n\n",
    "                Options:\\n{options_str}\\n\n",
    "                \n",
    "                Your response should strictly be in this format: option_id. Followed by no text from the option.\n",
    "\n",
    "                If the question has 'Please select all that apply then it is a multiple correct question. In this case, list each selected option_id separated by commas.\n",
    "                For example, 'option_1, option_3'.\n",
    "                \n",
    "                Don't give any explanations for your answers.\n",
    "                [/INST]\n",
    "              \"\"\"\n",
    "\n",
    "    # Call the Replicate API\n",
    "    output = replicate.run(\n",
    "        \"meta/llama-2-7b-chat:f1d50bb24186c52daae319ca8366e53debdaa9e0ae7ff976e918df752732ccc4\",\n",
    "        input={\n",
    "            \"top_p\": 1,\n",
    "            \"prompt\": prompt,\n",
    "            \"system_prompt\": f\"You are a {profile_desc}.\",\n",
    "            \"temperature\": 0.75,\n",
    "            \"repetition_penalty\": 1,\n",
    "            \"stop_sequences\": stop_sequences\n",
    "        }\n",
    "    )\n",
    "\n",
    "    # Collecting and processing the output\n",
    "    output_text = \"\".join(str(item) for item in output)\n",
    "    return output_text.strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_responses = []\n",
    "# prompt_id = 1\n",
    "# for profile in custom_profiles:\n",
    "#     print(f\"Generating responses for profile: {profile}...\")\n",
    "#     responses_for_profile = []\n",
    "#     for q in questionnaire:\n",
    "#         response = call_replicate(q['question'], profile, q['answers'])\n",
    "#         option_ids = parse_response(response, q['answers'])\n",
    "#         responses_for_profile.append({\n",
    "#             \"Question\": q['question'],\n",
    "#             \"Answer\": option_ids\n",
    "#         })\n",
    "\n",
    "#     all_responses.append({\n",
    "#         \"prompt_id\": prompt_id,\n",
    "#         \"profile\": profile,\n",
    "#         \"Responses\": responses_for_profile\n",
    "#     })\n",
    "#     prompt_id += 1\n",
    "#     print(f\"Received all responses for profile: {profile}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating responses for profile: ('18-22 years old', 'Woman', 'Asian', 'Bachelor’s degree', 'Less than 1 year')...\n",
      "Received all responses for profile: ('18-22 years old', 'Woman', 'Asian', 'Bachelor’s degree', 'Less than 1 year')\n",
      "Generating responses for profile: ('27-35 years old', 'Man', 'White', 'Professional degree', '3-5 years')...\n",
      "Received all responses for profile: ('27-35 years old', 'Man', 'White', 'Professional degree', '3-5 years')\n",
      "Generating responses for profile: ('23-26 years old', 'Woman', 'White', \"Master's degree\", '1-3 years')...\n",
      "Received all responses for profile: ('23-26 years old', 'Woman', 'White', \"Master's degree\", '1-3 years')\n",
      "Generating responses for profile: ('27-35 years old', 'Man', 'Asian', \"Bachelor's degree\", 'Less than 1 year')...\n",
      "Received all responses for profile: ('27-35 years old', 'Man', 'Asian', \"Bachelor's degree\", 'Less than 1 year')\n",
      "Generating responses for profile: ('18-22 years old', 'Woman', 'White', 'Professional degree', '3-5 years')...\n",
      "Received all responses for profile: ('18-22 years old', 'Woman', 'White', 'Professional degree', '3-5 years')\n",
      "Generating responses for profile: ('23-26 years old', 'Man', 'Asian', \"Master's degree\", 'Less than 1 year')...\n",
      "Received all responses for profile: ('23-26 years old', 'Man', 'Asian', \"Master's degree\", 'Less than 1 year')\n",
      "Generating responses for profile: ('27-35 years old', 'Woman', 'White', \"Bachelor's degree\", '1-3 years')...\n",
      "Received all responses for profile: ('27-35 years old', 'Woman', 'White', \"Bachelor's degree\", '1-3 years')\n",
      "Generating responses for profile: ('18-22 years old', 'Man', 'Asian', 'Professional degree', '1-3 years')...\n",
      "Received all responses for profile: ('18-22 years old', 'Man', 'Asian', 'Professional degree', '1-3 years')\n",
      "Generating responses for profile: ('23-26 years old', 'Woman', 'Asian', 'Bachelor’s degree', '3-5 years')...\n",
      "Received all responses for profile: ('23-26 years old', 'Woman', 'Asian', 'Bachelor’s degree', '3-5 years')\n",
      "Generating responses for profile: ('27-35 years old', 'Man', 'White', 'Master’s degree', 'Less than 1 year')...\n",
      "Received all responses for profile: ('27-35 years old', 'Man', 'White', 'Master’s degree', 'Less than 1 year')\n"
     ]
    }
   ],
   "source": [
    "all_responses = []\n",
    "prompt_id = 1\n",
    "for profile in custom_profiles:\n",
    "    print(f\"Generating responses for profile: {profile}...\")\n",
    "    responses_for_profile = []\n",
    "    for q in questionnaire:\n",
    "        next_question_start = \"Next Question Start Text\"  # Modify this as needed\n",
    "        response = call_replicate(q['question'], profile, q['answers'], next_question_start)\n",
    "        option_id = parse_response(response, q['answers'])\n",
    "\n",
    "        responses_for_profile.append({\n",
    "            \"Question\": q['question'],\n",
    "            \"Answer\": option_id\n",
    "        })\n",
    "\n",
    "    all_responses.append({\n",
    "        \"prompt_id\": prompt_id,\n",
    "        \"profile\": profile,\n",
    "        \"Responses\": responses_for_profile\n",
    "    })\n",
    "    prompt_id += 1\n",
    "    print(f\"Received all responses for profile: {profile}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to JSON\n",
    "json_filename = 'llama2_profile_responses.json'\n",
    "with open(json_filename, 'w', encoding='utf-8') as f:\n",
    "    json.dump(all_responses, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Convert to CSV\n",
    "def json_to_csv(json_file_path, csv_file_path):\n",
    "    with open(json_file_path, 'r', encoding='utf-8') as file:\n",
    "        data = json.load(file)\n",
    "\n",
    "    with open(csv_file_path, 'w', newline='', encoding='utf-8') as csvfile:\n",
    "        writer = csv.writer(csvfile)\n",
    "        header = ['Prompt ID', 'Profile', 'Question', 'Answer']\n",
    "        writer.writerow(header)\n",
    "\n",
    "        for entry in data:\n",
    "            profile = \", \".join(entry[\"profile\"])\n",
    "            for resp in entry[\"Responses\"]:\n",
    "                writer.writerow([\n",
    "                    entry[\"prompt_id\"], \n",
    "                    profile, \n",
    "                    resp[\"Question\"], \n",
    "                    resp[\"Answer\"]\n",
    "                ])\n",
    "\n",
    "csv_filename = 'llama2_profile_responses.csv'\n",
    "json_to_csv(json_filename, csv_filename)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
