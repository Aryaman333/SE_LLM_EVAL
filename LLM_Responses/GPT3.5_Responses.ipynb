{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai==0.28 in /usr/local/lib/python3.10/site-packages (0.28.0)\n",
      "Requirement already satisfied: requests>=2.20 in /usr/local/lib/python3.10/site-packages (from openai==0.28) (2.31.0)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/site-packages (from openai==0.28) (4.66.2)\n",
      "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/site-packages (from openai==0.28) (3.9.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/site-packages (from requests>=2.20->openai==0.28) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/site-packages (from requests>=2.20->openai==0.28) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/site-packages (from requests>=2.20->openai==0.28) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/site-packages (from requests>=2.20->openai==0.28) (2024.2.2)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/site-packages (from aiohttp->openai==0.28) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/site-packages (from aiohttp->openai==0.28) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/site-packages (from aiohttp->openai==0.28) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/site-packages (from aiohttp->openai==0.28) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/site-packages (from aiohttp->openai==0.28) (1.9.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/site-packages (from aiohttp->openai==0.28) (4.0.3)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3.10 -m pip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install openai==0.28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import csv\n",
    "import openai\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set OpenAI Key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai.api_key = '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'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Profile Attributes and select custom profiles for diversity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_profiles = [\n",
    "    (\"18-22 years old\", \"Woman\", \"Asian\", \"Bachelor’s degree\", \"Less than 1 year\"),\n",
    "    (\"27-35 years old\", \"Man\", \"White\", \"Professional degree\", \"3-5 years\"),\n",
    "    (\"23-26 years old\", \"Woman\", \"White\", \"Master's degree\", \"1-3 years\"),\n",
    "    (\"27-35 years old\", \"Man\", \"Asian\", \"Bachelor's degree\", \"Less than 1 year\"),\n",
    "    (\"18-22 years old\", \"Woman\", \"White\", \"Professional degree\", \"3-5 years\"),\n",
    "    (\"23-26 years old\", \"Man\", \"Asian\", \"Master's degree\", \"Less than 1 year\"),\n",
    "    (\"27-35 years old\", \"Woman\", \"White\", \"Bachelor's degree\", \"1-3 years\"),\n",
    "    (\"18-22 years old\", \"Man\", \"Asian\", \"Professional degree\", \"1-3 years\"),\n",
    "    (\"23-26 years old\", \"Woman\", \"Asian\", \"Bachelor’s degree\", \"3-5 years\"),\n",
    "    (\"27-35 years old\", \"Man\", \"White\", \"Master’s degree\", \"Less than 1 year\"),\n",
    "\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questionnaire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the questionnaire\n",
    "questionnaire = [\n",
    "    {\n",
    "        \"question\": \"What is your preferred development environment?\",\n",
    "        \"answers\": {\n",
    "            \"option_1\": \"Windows\",\n",
    "            \"option_2\": \"macOS\",\n",
    "            \"option_3\": \"Linux\",\n",
    "            \"option_4\": \"Other:\"\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"How do you learn to code? Please select all that apply.\",\n",
    "        \"answers\": {\n",
    "            \"option_1\": \"Online Courses or Certification\",\n",
    "            \"option_2\": \"Books\",\n",
    "            \"option_3\": \"School (i.e., University, College, etc.)\",\n",
    "            \"option_4\": \"Coding Bootcamp\",\n",
    "            \"option_5\": \"Other:\"\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"What is the biggest challenge you face as a developer?\",\n",
    "        \"answers\": {\n",
    "            \"option_1\": \"Keeping up with new technologies\",\n",
    "            \"option_2\": \"Work-life balance\",\n",
    "            \"option_3\": \"Understanding existing codebases\",\n",
    "            \"option_4\": \"Time management\"\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"When choosing a programming language for a new project you prioritize:\",\n",
    "        \"answers\": {\n",
    "            \"option_1\": \"The language's performance and scalability\",\n",
    "            \"option_2\": \"The development team's familiarity with the language\",\n",
    "            \"option_3\": \"The language's community support and ecosystem\",\n",
    "            \"option_4\": \"The specific requirements of the project\"\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"How do you communicate effectively with teammates to collaborate while adhering to the timelines?\",\n",
    "        \"answers\": {\n",
    "            \"option_1\": \"Use project management tools to assign tasks and track progress ensuring everyone is aware of deadlines.\",\n",
    "            \"option_2\": \"Schedule regular meetings for updates and coordination but keep them concise to avoid taking too much time away from work.\",\n",
    "            \"option_3\": \"Rely on informal chats and emails for quick updates trusting team members to manage their time efficiently.\",\n",
    "            \"option_4\": \"Implement a combination of written documentation for clarity and regular check-ins for personal engagement and immediate feedback.\"\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"How do you ensure that you stay up-to-date with industry changes as a software developer? Please select all that apply.\",\n",
    "        \"answers\": {\n",
    "            \"option_1\": \"Regularly read industry blogs, websites, and journals to learn about the latest trends and technologies.\",\n",
    "            \"option_2\": \"Attend workshops, conferences, and webinars to gain insights from industry leaders and peers.\",\n",
    "            \"option_3\": \"Participate in online courses and certification programs to acquire new skills and knowledge.\",\n",
    "            \"option_4\": \"Engage in open-source projects and coding communities to get hands-on experience with cutting-edge technologies.\"\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"How do you balance between innovation and meeting project deadlines?\",\n",
    "        \"answers\": {\n",
    "            \"option_1\": \"Prioritize innovation over deadlines\",\n",
    "            \"option_2\": \"Focus solely on meeting deadlines\",\n",
    "            \"option_3\": \"Allocate specific time for research and innovation\",\n",
    "            \"option_4\": \"Adjust project scopes to include innovation\"\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"Software development contributes to societal challenges by:. Please select all that apply\",\n",
    "        \"answers\": {\n",
    "            \"option_1\": \"Improving healthcare through technology, such as telemedicine platforms and health tracking apps\",\n",
    "            \"option_2\": \"Enhancing education with e-learning platforms, interactive learning tools, and virtual classrooms\",\n",
    "            \"option_3\": \"Addressing climate change with environmental monitoring systems, carbon footprint calculators, and energy efficiency applications\",\n",
    "            \"option_4\": \"Supporting economic development through fintech solutions, e-commerce platforms, and digital marketplaces\"\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"A company uses an AI system to monitor its employees' productivity. The AI suggests firing an employee based on low productivity, but the employee is going through a tough personal time. How should the company proceed?\",\n",
    "        \"answers\": {\n",
    "            \"option_1\": \"Follow the AI’s suggestion and fire the employee\",\n",
    "            \"option_2\": \"Ignore the AI’s suggestion and keep the employee\",\n",
    "            \"option_3\": \"Use the AI’s suggestion as one of several factors in the decision\",\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"You're assigned to a project that requires expertise in a programming language you're not familiar with. The deadline is tight. What is your strategy to tackle this situation?\",\n",
    "        \"answers\": {\n",
    "            \"option_1\": \"Spend time upfront to learn the basics of the language\",\n",
    "            \"option_2\": \"Use your existing knowledge and adapt as you go\",\n",
    "            \"option_3\": \"Seek assistance from a colleague who knows the language\",\n",
    "            \"option_4\": \"Suggest reallocating the project to someone with the necessary expertise\",\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"You discover a critical bug right before a software release. What immediate action do you take?\",\n",
    "        \"answers\": {\n",
    "            \"option_1\": \"Proceed with the release as planned and fix the bug in a subsequent patch\",\n",
    "            \"option_2\": \"Delay the release to assess and fix the bug, ensuring the product meets quality standards\",\n",
    "            \"option_3\": \"Release a limited beta version to a select group of users for further testing while addressing the bug\",\n",
    "            \"option_4\": \"Communicate with stakeholders about the issue and seek their input on how to proceed\",\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"question\": \" In a professional setting, if your team is supposed to deliver a SaaS product within a two-day timeframe, and you discover a critical bug in the software, how would you address and handle this situation?\",\n",
    "        \"answers\": {\n",
    "            \"option_1\": \"Ignore the bug and proceed with the delivery as planned, with the intention of fixing the bug in the next update.\",\n",
    "            \"option_2\": \"Inform your team leader or project manager about the bug immediately, and work collaboratively to assess its impact and decide on the next steps\",\n",
    "            \"option_3\": \"Delay the delivery without informing stakeholders to buy time for fixing the bug\",\n",
    "            \"option_4\": \"Document the bug and send an email to the client explaining the issue, suggesting a new timeline for delivery\",\n",
    "            \"option_5\": \"Prioritize the bug based on its severity and impact, and if it's critical, reallocate resources to fix it immediately, even if this means pushing back the delivery date\",\n",
    "        }\n",
    "    },\n",
    "\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def call_gpt(messages, temperature=0.5):\n",
    "    try:\n",
    "        start_time = time.time()\n",
    "\n",
    "        response = openai.ChatCompletion.create(\n",
    "            model=\"gpt-3.5-turbo\",\n",
    "            messages=messages,\n",
    "            temperature=temperature,\n",
    "        )\n",
    "        end_time = time.time()\n",
    "        duration = end_time - start_time\n",
    "        print(f\"API Call Duration: {duration} seconds\")\n",
    "\n",
    "        return response.choices[0].message['content'], duration\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error in generating response: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def tailored_prompt(question, profile, answer_options):\n",
    "#     age, gender, ethnicity, education, exp = profile\n",
    "#     profile_desc = f\"{age} old {gender} of {ethnicity} ethnicity with a {education} and {exp} of coding experience\"\n",
    "\n",
    "#     # Constructing a string with all answer options\n",
    "#     options_str = \"\\n\".join([f\"{key}: {value}\" for key, value in answer_options.items()])\n",
    "\n",
    "#     # Prepare messages with context-setting system message\n",
    "#     messages = [\n",
    "#         {\n",
    "#             \"role\": \"system\",\n",
    "#             \"content\": f\"Given a profile of {profile_desc}, respond to the following question. \"\n",
    "#                        f\"Select the correct option or options from the list provided. \"\n",
    "#                        f\"Reply with the full text of the chosen option(s). If multiple options are correct, list them all separated by commas. For example, 'Windows, Linux'.\"\n",
    "#         },\n",
    "#         {\n",
    "#             \"role\": \"user\",\n",
    "#             \"content\": f\"{question}\\nOptions:\\n{options_str}\"\n",
    "#         }\n",
    "#     ]\n",
    "#     return messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def tailored_prompt(question, profile, answer_options):\n",
    "    age, gender, ethnicity, education, exp = profile\n",
    "\n",
    "    # Variations in profile description\n",
    "    profile_desc_options = [\n",
    "        f\"{age} old {gender} of {ethnicity} ethnicity with a {education} and {exp} of coding experience\",\n",
    "        f\"A {gender} in the age group {age}, from {ethnicity} background, holding a {education} and having {exp} experience\",\n",
    "        f\"Person of {ethnicity} ethnicity, {age} years old, with {education} and {exp} experience in the field, identifying as {gender}\"\n",
    "    ]\n",
    "    profile_desc = random.choice(profile_desc_options)\n",
    "\n",
    "    # Constructing a string with all answer options\n",
    "    options_str = \"\\n\".join([f\"{key}: {value}\" for key, value in answer_options.items()])\n",
    "\n",
    "    # Examples tailored to your questionnaire\n",
    "    example_responses = [\n",
    "        f\"If Windows is your preferred development environment, reply 'option_1: Windows'.\",\n",
    "        f\"If you prefer an environment not listed here, respond as 'option_4: Other: [Your Preference]'.\"\n",
    "        f\"If the question allows multiple answers and you agree with both A and B, respond 'option_1: A, option_2: B'.\",\n",
    "    ]\n",
    "    example_response = random.choice(example_responses)\n",
    "\n",
    "    # System messages with variability\n",
    "    system_messages = [\n",
    "        f\"Given a profile of {profile_desc}, respond to the following question. \"\n",
    "        f\"Select the correct option from the list provided. For example, {example_response}\",\n",
    "\n",
    "        f\"Imagine you are {profile_desc}. For the following question, choose the most suitable answer \"\n",
    "        f\"from the provided options. For example, {example_response}\",\n",
    "\n",
    "        f\"As someone who is {profile_desc}, how would you answer this question? Select from the available options.\"\n",
    "        f\"For example, {example_response}\"\n",
    "    ]\n",
    "    system_message = random.choice(system_messages)\n",
    "\n",
    "    # Prepare messages with context-setting system message\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": system_message\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": f\"{question}\\nOptions:\\n{options_str}\"\n",
    "        }\n",
    "    ]\n",
    "    return messages\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_response(response, answer_options):\n",
    "    selected_options = []\n",
    "    other_response = None\n",
    "    for option_id, option_text in answer_options.items():\n",
    "        if option_text in response:\n",
    "            selected_options.append(option_id)\n",
    "            if \"Other:\" in option_text:\n",
    "                other_response = response.split(option_text)[1].strip()\n",
    "    return selected_options, other_response\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API Call Duration: 0.7286169528961182 seconds\n",
      "API Call Duration: 0.5055322647094727 seconds\n",
      "API Call Duration: 0.6335299015045166 seconds\n",
      "API Call Duration: 0.7045800685882568 seconds\n",
      "API Call Duration: 0.7091808319091797 seconds\n",
      "API Call Duration: 1.9094078540802002 seconds\n",
      "API Call Duration: 0.7733509540557861 seconds\n",
      "API Call Duration: 1.808588981628418 seconds\n",
      "API Call Duration: 0.6233956813812256 seconds\n",
      "API Call Duration: 0.7236342430114746 seconds\n",
      "API Call Duration: 0.7089259624481201 seconds\n",
      "API Call Duration: 1.1132450103759766 seconds\n",
      "API Call Duration: 0.4208042621612549 seconds\n",
      "API Call Duration: 0.6235346794128418 seconds\n",
      "API Call Duration: 0.5046727657318115 seconds\n",
      "API Call Duration: 0.5109989643096924 seconds\n",
      "API Call Duration: 1.0219900608062744 seconds\n",
      "API Call Duration: 1.544438123703003 seconds\n",
      "API Call Duration: 0.4446232318878174 seconds\n",
      "API Call Duration: 1.6974198818206787 seconds\n",
      "API Call Duration: 0.5117380619049072 seconds\n",
      "API Call Duration: 0.4889709949493408 seconds\n",
      "API Call Duration: 0.5720698833465576 seconds\n",
      "API Call Duration: 1.3066737651824951 seconds\n",
      "API Call Duration: 0.3946256637573242 seconds\n",
      "API Call Duration: 0.9233710765838623 seconds\n",
      "API Call Duration: 0.762902021408081 seconds\n",
      "API Call Duration: 0.5164089202880859 seconds\n",
      "API Call Duration: 0.5995771884918213 seconds\n",
      "API Call Duration: 1.3958380222320557 seconds\n",
      "API Call Duration: 0.39288973808288574 seconds\n",
      "API Call Duration: 1.6036450862884521 seconds\n",
      "API Call Duration: 0.609112024307251 seconds\n",
      "API Call Duration: 0.44818902015686035 seconds\n",
      "API Call Duration: 0.5647168159484863 seconds\n",
      "API Call Duration: 1.3977558612823486 seconds\n",
      "API Call Duration: 0.30659031867980957 seconds\n",
      "API Call Duration: 0.5269076824188232 seconds\n",
      "API Call Duration: 0.3875007629394531 seconds\n",
      "API Call Duration: 0.5680148601531982 seconds\n",
      "API Call Duration: 0.8794879913330078 seconds\n",
      "API Call Duration: 2.042330265045166 seconds\n",
      "API Call Duration: 0.39757299423217773 seconds\n",
      "API Call Duration: 2.115847110748291 seconds\n",
      "API Call Duration: 0.6579089164733887 seconds\n",
      "API Call Duration: 0.6134200096130371 seconds\n",
      "API Call Duration: 0.7982630729675293 seconds\n",
      "API Call Duration: 1.0440130233764648 seconds\n",
      "API Call Duration: 0.41072535514831543 seconds\n",
      "API Call Duration: 0.7494022846221924 seconds\n",
      "API Call Duration: 0.37574100494384766 seconds\n",
      "API Call Duration: 0.7158422470092773 seconds\n",
      "API Call Duration: 0.7165460586547852 seconds\n",
      "API Call Duration: 1.8433239459991455 seconds\n",
      "API Call Duration: 0.5120501518249512 seconds\n",
      "API Call Duration: 2.0473320484161377 seconds\n",
      "API Call Duration: 1.7327628135681152 seconds\n",
      "API Call Duration: 0.5709240436553955 seconds\n",
      "API Call Duration: 0.6963379383087158 seconds\n",
      "API Call Duration: 2.476785898208618 seconds\n",
      "API Call Duration: 0.4076507091522217 seconds\n",
      "API Call Duration: 0.9724740982055664 seconds\n",
      "API Call Duration: 0.5125901699066162 seconds\n",
      "API Call Duration: 0.5615170001983643 seconds\n",
      "API Call Duration: 0.7680697441101074 seconds\n",
      "API Call Duration: 1.5835719108581543 seconds\n",
      "API Call Duration: 0.3420710563659668 seconds\n",
      "API Call Duration: 1.8626837730407715 seconds\n",
      "API Call Duration: 0.761254072189331 seconds\n",
      "API Call Duration: 0.7196300029754639 seconds\n",
      "API Call Duration: 0.9333329200744629 seconds\n",
      "API Call Duration: 0.9470109939575195 seconds\n",
      "API Call Duration: 0.42520809173583984 seconds\n",
      "API Call Duration: 0.46567702293395996 seconds\n",
      "API Call Duration: 0.39290595054626465 seconds\n",
      "API Call Duration: 0.7444219589233398 seconds\n",
      "API Call Duration: 0.9375989437103271 seconds\n",
      "API Call Duration: 1.9688420295715332 seconds\n",
      "API Call Duration: 0.7265620231628418 seconds\n",
      "API Call Duration: 1.6300017833709717 seconds\n",
      "API Call Duration: 0.7167270183563232 seconds\n",
      "API Call Duration: 0.8181698322296143 seconds\n",
      "API Call Duration: 0.922821044921875 seconds\n",
      "API Call Duration: 1.245373010635376 seconds\n",
      "API Call Duration: 0.3584277629852295 seconds\n",
      "API Call Duration: 0.7855048179626465 seconds\n",
      "API Call Duration: 0.37598609924316406 seconds\n",
      "API Call Duration: 1.0230991840362549 seconds\n",
      "API Call Duration: 0.7171037197113037 seconds\n",
      "API Call Duration: 1.4336481094360352 seconds\n",
      "API Call Duration: 0.6153762340545654 seconds\n",
      "API Call Duration: 3.8465981483459473 seconds\n",
      "API Call Duration: 0.4118189811706543 seconds\n",
      "API Call Duration: 0.7439501285552979 seconds\n",
      "API Call Duration: 0.6304221153259277 seconds\n",
      "API Call Duration: 1.1279969215393066 seconds\n",
      "API Call Duration: 0.5100407600402832 seconds\n",
      "API Call Duration: 0.526047945022583 seconds\n",
      "API Call Duration: 0.49795007705688477 seconds\n",
      "API Call Duration: 0.7891190052032471 seconds\n",
      "API Call Duration: 1.095177173614502 seconds\n",
      "API Call Duration: 1.8785006999969482 seconds\n",
      "API Call Duration: 0.8453958034515381 seconds\n",
      "API Call Duration: 1.3304779529571533 seconds\n",
      "API Call Duration: 0.5412070751190186 seconds\n",
      "API Call Duration: 0.5297198295593262 seconds\n",
      "API Call Duration: 0.5776348114013672 seconds\n",
      "API Call Duration: 1.1157970428466797 seconds\n",
      "API Call Duration: 0.30550503730773926 seconds\n",
      "API Call Duration: 0.41033196449279785 seconds\n",
      "API Call Duration: 0.37502479553222656 seconds\n",
      "API Call Duration: 0.44501614570617676 seconds\n",
      "API Call Duration: 0.8196291923522949 seconds\n",
      "API Call Duration: 2.1506381034851074 seconds\n",
      "API Call Duration: 0.5104050636291504 seconds\n",
      "API Call Duration: 1.5631489753723145 seconds\n",
      "API Call Duration: 0.515146017074585 seconds\n",
      "API Call Duration: 0.7645130157470703 seconds\n",
      "API Call Duration: 0.6268129348754883 seconds\n",
      "API Call Duration: 1.1536271572113037 seconds\n"
     ]
    }
   ],
   "source": [
    "# Generate responses using tailored prompts for each custom profile\n",
    "all_responses = []\n",
    "prompt_id = 1\n",
    "for profile in custom_profiles:\n",
    "    responses_for_profile = []\n",
    "    for q in questionnaire:\n",
    "        messages = tailored_prompt(q['question'], profile, q['answers'])\n",
    "        response, duration = call_gpt(messages)\n",
    "\n",
    "        # Parse the response\n",
    "        option_ids, other_response = parse_response(response, q['answers'])\n",
    "\n",
    "        # Storing responses in a list\n",
    "        responses_for_profile.append({\n",
    "            \"Question\": q['question'],\n",
    "            \"Answer\": response,\n",
    "            \"option_ids\": option_ids,\n",
    "            \"other_response\": other_response\n",
    "        })\n",
    "\n",
    "    all_responses.append({\n",
    "        \"prompt_id\": prompt_id,\n",
    "        \"profile\": f\" of age: {profile[0]}, gender: {profile[1]}, {profile[2]}, with a {profile[3]} and {profile[4]} of coding experience\",\n",
    "        \"Responses\": responses_for_profile\n",
    "    })\n",
    "    prompt_id += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save responses to JSON\n",
    "json_filename = 'custom_profile_responses.json'\n",
    "with open(json_filename, 'w', encoding='utf-8') as f:\n",
    "    json.dump(all_responses, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to convert JSON to CSV\n",
    "def json_to_csv(json_file_path, csv_file_path):\n",
    "    with open(json_file_path, 'r', encoding='utf-8') as file:\n",
    "        data = json.load(file)\n",
    "\n",
    "    with open(csv_file_path, 'w', newline='', encoding='utf-8') as csvfile:\n",
    "        writer = csv.writer(csvfile)\n",
    "        header = ['Prompt ID', 'Profile', 'Question', 'Answer', 'Option IDs', 'Other Response']\n",
    "        writer.writerow(header)\n",
    "\n",
    "        for entry in data:\n",
    "            for resp in entry[\"Responses\"]:\n",
    "                writer.writerow([\n",
    "                    entry[\"prompt_id\"], \n",
    "                    entry[\"profile\"], \n",
    "                    resp[\"Question\"], \n",
    "                    resp[\"Answer\"], \n",
    "                    ', '.join(resp[\"option_ids\"]), \n",
    "                    resp[\"other_response\"] or \"\"\n",
    "                ])\n",
    "\n",
    "# Convert JSON to CSV\n",
    "csv_filename = 'custom_profile_responses.csv'\n",
    "json_to_csv(json_filename, csv_filename)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
